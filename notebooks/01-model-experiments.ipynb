{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn as sk\n",
    "from sklearn import (\n",
    "    model_selection,\n",
    "    preprocessing,\n",
    "    dummy,\n",
    "    metrics,\n",
    "    ensemble,\n",
    "    tree,\n",
    "    neighbors,\n",
    "    pipeline,\n",
    "    compose,\n",
    "    linear_model,\n",
    "    svm,\n",
    ")\n",
    "import xgboost as xgb\n",
    "\n",
    "ARTIFACTS_DIR = \"../models/artifacts/\"\n",
    "MODEL_DIR = \"../models/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7043, 20)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CAT_COLS = [\n",
    "    \"gender\",\n",
    "    \"SeniorCitizen\",\n",
    "    \"Partner\",\n",
    "    \"Dependents\",\n",
    "    \"PhoneService\",\n",
    "    \"MultipleLines\",\n",
    "    \"InternetService\",\n",
    "    \"OnlineSecurity\",\n",
    "    \"OnlineBackup\",\n",
    "    \"DeviceProtection\",\n",
    "    \"TechSupport\",\n",
    "    \"StreamingTV\",\n",
    "    \"StreamingMovies\",\n",
    "    \"Contract\",\n",
    "    \"PaperlessBilling\",\n",
    "    \"PaymentMethod\",\n",
    "]\n",
    "NUM_COLS = [\"tenure\", \"MonthlyCharges\", \"TotalCharges\"]\n",
    "TARGET = [\"Churn\"]\n",
    "SEED = 69420\n",
    "\n",
    "df = pd.read_csv(\n",
    "    \"../data/WA_Fn-UseC_-Telco-Customer-Churn.csv\", usecols=CAT_COLS + NUM_COLS + TARGET\n",
    ")\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "CAT_COLS_OHE = [\"PaymentMethod\", \"Contract\", \"InternetService\"]\n",
    "CAT_COLS_LE = list(set(CAT_COLS) - set(CAT_COLS_OHE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.TotalCharges = df.TotalCharges.replace(to_replace=\" \", value=\"0\")\n",
    "\n",
    "\n",
    "def custom_combiner(feature, category):\n",
    "    return str(feature) + \"_\" + type(category).__name__ + \"_\" + str(category)\n",
    "\n",
    "\n",
    "scaler = preprocessing.StandardScaler().set_output(transform=\"pandas\")\n",
    "encoder_ohe = preprocessing.OneHotEncoder(feature_name_combiner=custom_combiner)\n",
    "encoder_oe = preprocessing.OrdinalEncoder().set_output(transform=\"pandas\")\n",
    "target_preprocessor = preprocessing.LabelEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((6338, 19), (705, 19), (6338, 1), (705, 1))"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X, y = df.drop(columns=TARGET), df[TARGET]\n",
    "X_train, X_test, y_train, y_test = model_selection.train_test_split(\n",
    "    X, y, test_size=0.1, random_state=42\n",
    ")\n",
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6338, 10)\n",
      "(6338, 13)\n",
      "(6338, 3)\n",
      "(6338, 26)\n"
     ]
    }
   ],
   "source": [
    "# One-hot encoding\n",
    "X_ohe__train = X_train[CAT_COLS_OHE]\n",
    "encoder_ohe.fit(X_ohe__train)\n",
    "X_ohe_trans__train = encoder_ohe.transform(X_ohe__train)\n",
    "X_ohe_trans_df__train: pd.DataFrame = pd.DataFrame(\n",
    "    X_ohe_trans__train.toarray(), columns=encoder_ohe.get_feature_names_out()\n",
    ")\n",
    "\n",
    "print(X_ohe_trans__train.shape)\n",
    "\n",
    "# Ordinal Encoding\n",
    "X_oe__train = X_train[CAT_COLS_LE]\n",
    "encoder_oe.fit(X_oe__train)\n",
    "X_oe_trans__train = encoder_oe.transform(X_oe__train)\n",
    "print(X_oe_trans__train.shape)\n",
    "\n",
    "# Scale\n",
    "X_scale__train = X_train[NUM_COLS]\n",
    "scaler.fit(X_scale__train)\n",
    "X_scale_trans__train = scaler.transform(X_scale__train)\n",
    "print(X_scale_trans__train.shape)\n",
    "\n",
    "X_to_train = pd.concat(\n",
    "    [\n",
    "        X_ohe_trans_df__train.reset_index(drop=True),\n",
    "        X_oe_trans__train.reset_index(drop=True),\n",
    "        X_scale_trans__train.reset_index(drop=True),\n",
    "    ],\n",
    "    axis=1,\n",
    ")\n",
    "print(X_to_train.shape)\n",
    "\n",
    "\n",
    "# ----------------------------------------------- #\n",
    "X_ohe__test = X_test[CAT_COLS_OHE]\n",
    "X_ohe_trans__test = encoder_ohe.transform(X_ohe__test)\n",
    "X_ohe_trans__test: pd.DataFrame = pd.DataFrame(\n",
    "    X_ohe_trans__test.toarray(), columns=encoder_ohe.get_feature_names_out()\n",
    ")\n",
    "\n",
    "X_oe__test = X_test[CAT_COLS_LE]\n",
    "X_oe_trans__test = encoder_oe.transform(X_oe__test)\n",
    "\n",
    "X_scale__test = X_test[NUM_COLS]\n",
    "scaler.fit(X_scale__test)\n",
    "X_scale_trans__test = scaler.transform(X_scale__test)\n",
    "\n",
    "X_to_test = pd.concat(\n",
    "    [\n",
    "        X_ohe_trans__test.reset_index(drop=True),\n",
    "        X_oe_trans__test.reset_index(drop=True),\n",
    "        X_scale_trans__test.reset_index(drop=True),\n",
    "    ],\n",
    "    axis=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6987, 26)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6338,)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ishan\\Desktop\\programs\\pythonfiles\\churninator\\.venv\\lib\\site-packages\\sklearn\\preprocessing\\_label.py:97: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\Users\\ishan\\Desktop\\programs\\pythonfiles\\churninator\\.venv\\lib\\site-packages\\sklearn\\preprocessing\\_label.py:132: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n",
      "c:\\Users\\ishan\\Desktop\\programs\\pythonfiles\\churninator\\.venv\\lib\\site-packages\\sklearn\\preprocessing\\_label.py:132: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n"
     ]
    }
   ],
   "source": [
    "target_preprocessor.fit(y_train)\n",
    "y_train = target_preprocessor.transform(y_train)\n",
    "y_test = target_preprocessor.transform(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Found input variables with inconsistent numbers of samples: [6987, 6338]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 47\u001b[0m\n\u001b[0;32m     14\u001b[0m     \u001b[39mreturn\u001b[39;00m pd\u001b[39m.\u001b[39mDataFrame\u001b[39m.\u001b[39mfrom_dict(results)\n\u001b[0;32m     17\u001b[0m models \u001b[39m=\u001b[39m [\n\u001b[0;32m     18\u001b[0m     (\n\u001b[0;32m     19\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mdummy_classifier\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     44\u001b[0m     ),\n\u001b[0;32m     45\u001b[0m ]\n\u001b[1;32m---> 47\u001b[0m results \u001b[39m=\u001b[39m run_experiments(models)\n\u001b[0;32m     48\u001b[0m results\u001b[39m.\u001b[39mcolumns \u001b[39m=\u001b[39m [\u001b[39m\"\u001b[39m\u001b[39maccuracy\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mprecision\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mrecall\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mfscore\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[0;32m     49\u001b[0m results \u001b[39m=\u001b[39m results\u001b[39m.\u001b[39msort_values(by\u001b[39m=\u001b[39m[\u001b[39m\"\u001b[39m\u001b[39mfscore\u001b[39m\u001b[39m\"\u001b[39m], ascending\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n",
      "Cell \u001b[1;32mIn[9], line 6\u001b[0m, in \u001b[0;36mrun_experiments\u001b[1;34m(models, X_train, y_train, X_test, y_test, seed)\u001b[0m\n\u001b[0;32m      4\u001b[0m results \u001b[39m=\u001b[39m \u001b[39mdict\u001b[39m()\n\u001b[0;32m      5\u001b[0m \u001b[39mfor\u001b[39;00m name, model \u001b[39min\u001b[39;00m models:\n\u001b[1;32m----> 6\u001b[0m     model\u001b[39m.\u001b[39;49mfit(X_train, y_train)\n\u001b[0;32m      7\u001b[0m     predictions \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39mpredict(X_test)\n\u001b[0;32m      8\u001b[0m     accuracy \u001b[39m=\u001b[39m metrics\u001b[39m.\u001b[39maccuracy_score(y_test, predictions)\n",
      "File \u001b[1;32mc:\\Users\\ishan\\Desktop\\programs\\pythonfiles\\churninator\\.venv\\lib\\site-packages\\sklearn\\base.py:1151\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1144\u001b[0m     estimator\u001b[39m.\u001b[39m_validate_params()\n\u001b[0;32m   1146\u001b[0m \u001b[39mwith\u001b[39;00m config_context(\n\u001b[0;32m   1147\u001b[0m     skip_parameter_validation\u001b[39m=\u001b[39m(\n\u001b[0;32m   1148\u001b[0m         prefer_skip_nested_validation \u001b[39mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1149\u001b[0m     )\n\u001b[0;32m   1150\u001b[0m ):\n\u001b[1;32m-> 1151\u001b[0m     \u001b[39mreturn\u001b[39;00m fit_method(estimator, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\ishan\\Desktop\\programs\\pythonfiles\\churninator\\.venv\\lib\\site-packages\\sklearn\\dummy.py:198\u001b[0m, in \u001b[0;36mDummyClassifier.fit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    194\u001b[0m     y \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mreshape(y, (\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m, \u001b[39m1\u001b[39m))\n\u001b[0;32m    196\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mn_outputs_ \u001b[39m=\u001b[39m y\u001b[39m.\u001b[39mshape[\u001b[39m1\u001b[39m]\n\u001b[1;32m--> 198\u001b[0m check_consistent_length(X, y)\n\u001b[0;32m    200\u001b[0m \u001b[39mif\u001b[39;00m sample_weight \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    201\u001b[0m     sample_weight \u001b[39m=\u001b[39m _check_sample_weight(sample_weight, X)\n",
      "File \u001b[1;32mc:\\Users\\ishan\\Desktop\\programs\\pythonfiles\\churninator\\.venv\\lib\\site-packages\\sklearn\\utils\\validation.py:409\u001b[0m, in \u001b[0;36mcheck_consistent_length\u001b[1;34m(*arrays)\u001b[0m\n\u001b[0;32m    407\u001b[0m uniques \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39munique(lengths)\n\u001b[0;32m    408\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(uniques) \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m--> 409\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    410\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mFound input variables with inconsistent numbers of samples: \u001b[39m\u001b[39m%r\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[0;32m    411\u001b[0m         \u001b[39m%\u001b[39m [\u001b[39mint\u001b[39m(l) \u001b[39mfor\u001b[39;00m l \u001b[39min\u001b[39;00m lengths]\n\u001b[0;32m    412\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [6987, 6338]"
     ]
    }
   ],
   "source": [
    "def run_experiments(\n",
    "    models, X_train=X_train, y_train=y_train, X_test=X_test, y_test=y_test, seed=SEED\n",
    ") -> pd.DataFrame:\n",
    "    results = dict()\n",
    "    for name, model in models:\n",
    "        model.fit(X_train, y_train)\n",
    "        predictions = model.predict(X_test)\n",
    "        accuracy = metrics.accuracy_score(y_test, predictions)\n",
    "        precision, recall, fscore, _ = metrics.precision_recall_fscore_support(\n",
    "            y_test, predictions, average=\"weighted\"\n",
    "        )\n",
    "        print(f\"{name} --> {fscore}\")\n",
    "        results[name] = (accuracy, precision, recall, fscore)\n",
    "    return pd.DataFrame.from_dict(results)\n",
    "\n",
    "\n",
    "models = [\n",
    "    (\n",
    "        \"dummy_classifier\",\n",
    "        dummy.DummyClassifier(random_state=SEED, strategy=\"most_frequent\"),\n",
    "    ),\n",
    "    (\"k_nearest_neighbors\", neighbors.KNeighborsClassifier()),\n",
    "    (\n",
    "        \"logistic_regression\",\n",
    "        linear_model.LogisticRegression(\n",
    "            random_state=SEED, solver=\"liblinear\", class_weight=\"balanced\"\n",
    "        ),\n",
    "    ),\n",
    "    (\"support_vector_machines\", svm.SVC(random_state=SEED, kernel=\"rbf\")),\n",
    "    (\"random_forest\", ensemble.RandomForestClassifier(random_state=SEED)),\n",
    "    (\"gradient_boosting\", ensemble.GradientBoostingClassifier(random_state=SEED)),\n",
    "    (\"decision_tree\", tree.DecisionTreeClassifier(random_state=SEED)),\n",
    "    (\"adaboost\", ensemble.AdaBoostClassifier()),\n",
    "    (\n",
    "        \"voting\",\n",
    "        ensemble.VotingClassifier(\n",
    "            estimators=[\n",
    "                (\"gbc\", ensemble.GradientBoostingClassifier()),\n",
    "                (\"lr\", linear_model.LogisticRegression()),\n",
    "                (\"abc\", ensemble.AdaBoostClassifier()),\n",
    "            ],\n",
    "            voting=\"soft\",\n",
    "        ),\n",
    "    ),\n",
    "]\n",
    "\n",
    "results = run_experiments(models)\n",
    "results.columns = [\"accuracy\", \"precision\", \"recall\", \"fscore\"]\n",
    "results = results.sort_values(by=[\"fscore\"], ascending=False)\n",
    "results"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
